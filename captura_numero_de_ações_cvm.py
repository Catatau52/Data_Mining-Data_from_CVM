# -*- coding: utf-8 -*-
"""Personal Project part 01 - Captura numero de ações CVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Du3U84Jn7erXRHCUUa-DPCiz_afQL_Ih

#Instalando bibliotecas
"""

!pip install wget

import pandas as pd
import numpy as np
import decimal
import os
import zipfile
from zipfile import ZipFile
import wget
import requests
import xml.etree.ElementTree as ET

"""#Acessando a base de dados da CVM"""

url_base = 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/'

"""Fazendo download dos arquivos"""

arquivos_zip = []
for ano in range(2011,2023+1):
  arquivos_zip.append(f'itr_cia_aberta_{ano}.zip')
arquivos_zip

#arq = 'itr_cia_aberta_2011'
#arq = 'itr_cia_aberta_2012'
#arq = 'itr_cia_aberta_2013'
#arq = 'itr_cia_aberta_2014'
#arq = 'itr_cia_aberta_2015'
#arq = 'itr_cia_aberta_2016'
#arq = 'itr_cia_aberta_2017'
#arq = 'itr_cia_aberta_2018'
#arq = 'itr_cia_aberta_2019'
#arq = 'itr_cia_aberta_2020'
#arq = 'itr_cia_aberta_2021'
arq = 'itr_cia_aberta_2022'
#for arq in arquivos_zip:
wget.download(url_base+arq+'.zip')

"""Extraindo zip e carregando .csv

"""

ZipFile(arq+'.zip', 'r').extractall('CVM')
df = pd.read_csv(f'CVM/{arq}.csv', sep=';', decimal=',', encoding='ISO-8859-1')
df = df.loc[df['VERSAO'] == 1]
df = df.drop(['VERSAO','CATEG_DOC','DT_RECEB'], axis=1)
df = df.reset_index()

df.loc[df['DENOM_CIA'] == 'RUMO MALHA SUL S.A.']

link_arquivo = df['LINK_DOC']
link_arquivo[89]

df[['Acoes_ON', 'Acoes_PN', 'Tes_ON','Tes_PN','Precisao']] = np.nan

"""Extraindo zip e carregando .xml"""

def fazer_download_arquivo(url, nome_arquivo):
    with open(nome_arquivo, 'wb') as arquivo:
      arquivo.write(requests.get(url).content)

    try:
        # Tenta abrir o arquivo ZIP
        ZipFile(f'arquivo_{index}.zip', 'r').extractall('Download')

    except zipfile.BadZipFile:
        # Trata o erro de arquivo ZIP corrompido
        print(f"Erro: O arquivo '{f'arquivo_{index}.zip'}' está corrompido.")
        # Aqui você pode tentar fazer o download novamente ou tomar alguma outra ação.
        # Exemplo: fazer o download novamente
        print("Fazendo download novamente...")
        fazer_download_arquivo(url, nome_arquivo)

# Lista os arquivos na pasta
    arquivos = os.listdir('Download')
    # Filtra apenas os arquivos XML
    arquivos_xml = [arquivo for arquivo in arquivos if arquivo.endswith('.xml')]
    # Abre o primeiro arquivo XML da lista
    primeiro_arquivo = os.path.join('Download', arquivos_xml[0])
    # Faz o parsing do arquivo XML
    # Carregar o arquivo XML
    tree = ET.parse(primeiro_arquivo)
    # Obter a raiz do documento XML
    root = tree.getroot()

    # Acessar elementos específicos
    Acoes_ON = root.find('.//CaptalIntegralizado/Ordinarias').text
    Acoes_PN = root.find('.//CaptalIntegralizado/Preferenciais').text
    Tes_ON = root.find('.//Tesouraria/Ordinarias').text
    Tes_PN = root.find('.//Tesouraria/Preferenciais').text

    print(f' total de ações Acoes_ON =  {Acoes_ON}')
    print(f' total de ações Acoes_PN =  {Acoes_PN}')
    print(f' total de ações Tes_ON =  {Tes_ON}')
    print(f' total de ações Tes_PN =  {Tes_PN}')

for index, url in enumerate(link_arquivo):
    if index < 1997:# or index == 762:
      continue
    nome_arquivo = f'arquivo_{index}.zip'

    fazer_download_arquivo(url, nome_arquivo)

    ZipFile(f'arquivo_{index}.zip', 'r').extractall('Download')

    # apaga o .zip
    os.remove(f'arquivo_{index}.zip')

    ################ PARA CAPTURA APARTIR DE 2022 #############################
    try:
        flagerror = False
        # Tenta abrir o arquivo xslx
        data = pd.read_excel('/content/Download/DadosDocumento.xlsx', sheet_name=0)

    except FileNotFoundError :
      flagerror = True
      # Defina o caminho para a pasta onde estão os arquivos XML
      pasta_xml = '/content/Download'
      # Lista os arquivos na pasta
      arquivos = os.listdir(pasta_xml)
      # Filtra apenas os arquivos XML
      arquivos_xml = [arquivo for arquivo in arquivos if arquivo.endswith('.xml')]
      # Verifica se há pelo menos um arquivo XML na pasta
      if len(arquivos_xml) > 0:
          # Abre o primeiro arquivo XML da lista
          primeiro_arquivo = os.path.join(pasta_xml, arquivos_xml[0])

          # Faz o parsing do arquivo XML
          tree = ET.parse(primeiro_arquivo)
          root = tree.getroot()
      # Percorre todos os arquivos do diretório
      # for arquivo in os.listdir('Download'):
      #     # Verifica se o arquivo é um arquivo zip
      #     if arquivo.endswith('.dfp'):
      #         # Caminho completo para o arquivo zip
      #         caminho_arquivo_zip = os.path.join('Download', arquivo)

      #         with zipfile.ZipFile(caminho_arquivo_zip, 'r') as zip_ref:
      #           # Extrai o arquivo especificado para o diretório atual
      #           zip_ref.extract('ComposicaoCapitalSocialDemonstracaoFinanceiraNegocios.xml', './')

      #           #Carregar o arquivo XML
      #           tree = ET.parse('ComposicaoCapitalSocialDemonstracaoFinanceiraNegocios.xml')
      #           # Obter a raiz do documento XML
      #           root = tree.getroot()

    ################ PARA CAPTURA APARTIR DE 2022 #############################

    if not flagerror:
      print('Data from XLSX')
      Acoes_ON = data.loc[0, 'Acoes Ordinarias Capital Integralizado']
      Acoes_PN = data.loc[0, 'Acoes Preferenciais Capital Integralizado']
      Tes_ON = data.loc[0, 'Acoes Ordinarias Tesouraria']
      Tes_PN = data.loc[0, 'Acoes Preferenciais Tesouraria']
      Precisao = data.loc[0, 'Precisao']
    if flagerror:
      flagerror = False
      print('Data from XML')
      Acoes_ON = root.find('.//CaptalIntegralizado/Ordinarias').text
      Acoes_PN = root.find('.//CaptalIntegralizado/Preferenciais').text
      Tes_ON = root.find('.//Tesouraria/Ordinarias').text
      Tes_PN = root.find('.//Tesouraria/Preferenciais').text
      Precisao = np.NaN

     # apaga os arquivos da pasta download
    for arquivo in os.listdir('Download'):
        caminho_arquivo = os.path.join('Download', arquivo)
        if os.path.isfile(caminho_arquivo):
            os.remove(caminho_arquivo)

    df.loc[index, ['Acoes_ON', 'Acoes_PN', 'Tes_ON','Tes_PN', 'Precisao']] = [Acoes_ON, Acoes_PN, Tes_ON, Tes_PN, Precisao]

    # Obter o texto do elemento
    print(f'total de empresas capturadas {index}/{df.shape[0]} - ON = {Acoes_ON} , PN = {Acoes_PN}')

################ PARA CAPTURA ATÉ 2021 #############################
# for index, url in enumerate(link_arquivo):
#     #if index < 1629:# or index == 762:
#     #  continue

#     nome_arquivo = f'arquivo_{index}.zip'

#     fazer_download_arquivo(url, nome_arquivo)

#     ZipFile(f'arquivo_{index}.zip', 'r').extractall('Download')

#     # apaga o .zip
#     os.remove(f'arquivo_{index}.zip')

#     # Percorre todos os arquivos do diretório
#     for arquivo in os.listdir('Download'):
#         # Verifica se o arquivo é um arquivo zip
#         if arquivo.endswith('.itr'):
#             # Caminho completo para o arquivo zip
#             caminho_arquivo_zip = os.path.join('Download', arquivo)

#             # Cria uma instância da classe ZipFile para o arquivo zip
#             #with zipfile.ZipFile(caminho_arquivo_zip, 'r') as zip_ref:
#                 # Extrai todo o conteúdo do arquivo zip para o diretório atual
#               #zip_ref.extractall('Download')

#             with zipfile.ZipFile(caminho_arquivo_zip, 'r') as zip_ref:
#               # Extrai o arquivo especificado para o diretório atual
#               zip_ref.extract('ComposicaoCapitalSocialDemonstracaoFinanceiraNegocios.xml', './')

#     # apaga os arquivos da pasta download
#     #for arquivo in os.listdir('Download'):
#     #    caminho_arquivo = os.path.join('Download', arquivo)
#     #    if os.path.isfile(caminho_arquivo):
#     #        os.remove(caminho_arquivo)

#     # Carregar o arquivo XML
#     tree = ET.parse('ComposicaoCapitalSocialDemonstracaoFinanceiraNegocios.xml')

#     # Obter a raiz do documento XML
#     root = tree.getroot()

#     # Acessar elementos específicos
#     #elemento = root.find('.//QuantidadeTotalAcaoCapitalIntegralizado')
#     Acoes_ON = root.find('.//QuantidadeAcaoOrdinariaCapitalIntegralizado').text
#     Acoes_PN = root.find('.//QuantidadeAcaoPreferencialCapitalIntegralizado').text
#     Tes_ON = root.find('.//QuantidadeAcaoOrdinariaTesouraria').text
#     Tes_PN = root.find('.//QuantidadeAcaoPreferencialTesouraria').text

#     # Obter o texto do elemento
#     #texto = Acoes_ON.text
#     print(f'{df.shape[0]} / total de ações para o index {index} = {Acoes_ON + Acoes_PN}')
#     #df.loc[index,'TOTAL_ACOES'] = texto
#     df.loc[index, ['Acoes_ON', 'Acoes_PN', 'Tes_ON','Tes_PN']] = [Acoes_ON, Acoes_PN, Tes_ON, Tes_PN]
#   #print(f'{index} arquivos baixados')

df.head(10)

total_zeros = ((df['Acoes_ON'] == '0') + (df['Acoes_PN'] == '0')).sum()
print("Total de resultado de empresas em ações em circulação" + ":", total_zeros)

linhas_filtradas = df.loc[(df['Acoes_ON'] == '0') & (df['Acoes_PN'] == '0')]
linhas_filtradas

# Obtenha os índices das linhas que satisfazem o filtro
#indices_filtrados = df.loc[linhas_filtradas].index

# Calcule os índices da linha anterior e posterior
#indice_anterior = indices_filtrados - 1
#indice_posterior = indices_filtrados + 1

# Imprima a linha anterior, a linha do filtro e a linha posterior
#linhas_desejadas = df.loc[indice_anterior.union(indices_filtrados).union(indice_posterior)]
#linhas_desejadas

df = df.drop(['index','ID_DOC','LINK_DOC'], axis =1 )

df = df.drop_duplicates()

df.to_csv('base_2022_tri_num_acoes.csv', index=False)

#################################

df1 = pd.read_csv('/content/base_2019_tri_num_acoes_1.csv', sep=',', decimal=',', encoding='ISO-8859-1')

df1

novo_dataframe = pd.merge(df, df1, on=['CNPJ_CIA','DT_REFER','DENOM_CIA','CD_CVM'], how='inner')

# Preencher NaN na 'Coluna2' com os valores da 'Coluna1'
novo_dataframe['Acoes_ON_x'] = novo_dataframe['Acoes_ON_x'].fillna(novo_dataframe['Acoes_ON_y'])
novo_dataframe['Acoes_PN_x'] = novo_dataframe['Acoes_PN_x'].fillna(novo_dataframe['Acoes_PN_y'])
novo_dataframe['Tes_ON_x'] = novo_dataframe['Tes_ON_x'].fillna(novo_dataframe['Tes_ON_y'])
novo_dataframe['Tes_PN_x'] = novo_dataframe['Tes_PN_x'].fillna(novo_dataframe['Tes_PN_y'])

novo_dataframe = novo_dataframe.drop(['Acoes_ON_y','Acoes_PN_y','Tes_ON_y','Tes_PN_y'], axis =1 )
novo_dataframe = novo_dataframe.rename(columns={'Acoes_ON_x' : 'Acoes_ON', 'Acoes_PN_x' : 'Acoes_PN', 'Tes_ON_x' : 'Tes_ON', 'Tes_PN_x' : 'Tes_PN'})

novo_dataframe = novo_dataframe.drop_duplicates()

novo_dataframe.dtypes

novo_dataframe.to_csv('base_2019_tri_num_acoes.csv', index=False)

novo_dataframe